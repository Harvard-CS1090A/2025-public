{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f269959a",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS1090A Introduction to Data Science "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e88efb0",
   "metadata": {},
   "source": [
    "# Section 10: Decision Trees\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2025**<br/>\n",
    "**Instructors**: Pavlos Protopapas and Kevin Rader<br/>\n",
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54fd45-550c-44a6-88b7-7aa6d3184172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the name of the zip file containing your assets\n",
    "assets_zip_name = \"notebook_assets.zip\"\n",
    "\n",
    "# Define the directories that should be present after extraction\n",
    "expected_dirs = [\"data\", \"fig\"]\n",
    "\n",
    "# Construct the raw GitHub URL for the zip file\n",
    "github_raw_url = f\"https://github.com/Harvard-CS1090A/2025-public/raw/main/sec10/{assets_zip_name}\"\n",
    "\n",
    "# Check if running in Google Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Running in Google Colab. Checking for necessary files...\")\n",
    "\n",
    "    # Check if the expected directories already exist\n",
    "    all_dirs_exist = True\n",
    "    for d in expected_dirs:\n",
    "        if not os.path.isdir(d):\n",
    "            all_dirs_exist = False\n",
    "            break\n",
    "\n",
    "    if all_dirs_exist:\n",
    "        print(\"Required directories already exist. Skipping download.\")\n",
    "    else:\n",
    "        print(f\"Required directories not found. Downloading {assets_zip_name} from GitHub...\")\n",
    "\n",
    "        try:\n",
    "            # Download the zip file\n",
    "            subprocess.run(['wget', '-q', github_raw_url], check=True)\n",
    "            print(f\"Downloaded {assets_zip_name}.\")\n",
    "\n",
    "            # Unzip the file\n",
    "            subprocess.run(['unzip', '-q', assets_zip_name], check=True)\n",
    "            print(f\"Extracted {assets_zip_name}.\")\n",
    "\n",
    "            # Clean up the zip file\n",
    "            subprocess.run(['rm', assets_zip_name], check=True)\n",
    "            print(f\"Removed {assets_zip_name}.\")\n",
    "\n",
    "            print(\"All necessary files are now available.\")\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error during file download or extraction: {e}\", file=sys.stderr)\n",
    "        except FileNotFoundError:\n",
    "            print(\"wget or unzip command not found. Please ensure they are installed.\", file=sys.stderr)\n",
    "\n",
    "else:\n",
    "    print(\"Not running in Google Colab. Assuming files are locally available.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42415478",
   "metadata": {},
   "source": [
    "---------\n",
    "## Decision Tree Conceptual Review\n",
    "\n",
    "#### The Idea: Decision Trees are just flowcharts and are interpretable!\n",
    "\n",
    "<img src=\"fig/flowchart.png\" alt=\"how to fix anything\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "It turns out that simple flow charts can be formulated as mathematical models for classification and these models have the properties we desire:\n",
    " - interpretable by humans \n",
    " - have sufficiently complex decision boundaries \n",
    " - the decision boundaries are locally linear, each component of the decision boundary is simple to describe mathematically. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f436269f",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "#### Let's review some theory.\n",
    "\n",
    "How do we build decision trees? We use a greedy approach:\n",
    " 1. Start with an empty decision tree (undivided feature space) \n",
    " 2. Choose the ‚Äòoptimal‚Äô predictor on which to split and choose the ‚Äòoptimal‚Äô threshold value for splitting by applying a **splitting criterion (1)**\n",
    " 3. Recurse on on each new node until **stopping condition (2)** is met\n",
    " \n",
    "For classification, we label each region in the model with the label of the class to which the majority of the points within the region belong. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d465b3e1",
   "metadata": {},
   "source": [
    "#### So we need a (1) splitting criterion and a (2) stopping condition:\n",
    "\n",
    "  #### (1) Splitting criterion \n",
    "<img src=\"fig/split1.png\" alt=\"split1\" width=\"70%\"/>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"fig/classification error.png\" alt=\"classification error\"/>\n",
    "\n",
    "---\n",
    "<img src=\"fig/split2.png\" alt=\"split2\" width=\"70%\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f729359",
   "metadata": {},
   "source": [
    "<img src=\"fig/tree_loss.png\" alt=\"tree_adj\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31b61758",
   "metadata": {},
   "source": [
    "#### (2) Stopping condition\n",
    "\n",
    "If we don‚Äôt terminate the decision tree learning algorithm manually, the tree will continue to grow until each region defined by the model possibly contains exactly one training point (and the model attains 100% training accuracy). **Not stopping while building a deeper and deeper tree = 100% training accuracy; What will your test accuracy be? What can we do to fix this?**\n",
    "\n",
    "To prevent the **overfitting** from happening, we could \n",
    "- Stop the algorithm at a particular depth. (=**not too deep**)\n",
    "- Don't split a region if all instances in the region belong to the same class. (=**stop when subtree is pure**)\n",
    "- Don't split a region if the number of instances in the sub-region will fall below pre-defined threshold (min_samples_leaf). (=**not too specific/small subtree**)\n",
    "- Don't use too many splits in the tree (=**not too many splits / not too complex global tree**)\n",
    "- Be content with <100% accuracy training set...\n",
    "\n",
    "-------------\n",
    "\n",
    "#### Done with theory, let's get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "\n",
    "#new model objects\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cc814",
   "metadata": {},
   "source": [
    "## Decision Tree from scratch\n",
    "\n",
    "In this exercise we'll build a portion of a decision tree classifier from scratch and compare our results to the `sklearn` implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d36fe",
   "metadata": {},
   "source": [
    "Our toy dataset consists of two predictors and a binary class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa15dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframe in\n",
    "tree_df = pd.read_csv('data/two_classes.csv')\n",
    "# Inspect the top 5 rows\n",
    "tree_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4741b12",
   "metadata": {},
   "source": [
    "Visualizing the data we can imagine what the ideal decision boundaries might look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a33e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to visualize class patterns\n",
    "\n",
    "# Create figure of specific size and the axes objects\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "# Scatter the data points\n",
    "# Other colormaps could be found here:\n",
    "# https://stackoverflow.com/questions/34314356/how-to-view-all-colormaps-available-in-matplotlib\n",
    "scatter = ax.scatter(tree_df['x1'], tree_df['x2'], c=tree_df['y'], cmap='rainbow')\n",
    "\n",
    "# Create a legend object with title \"Classes\" and specified location on the plot\n",
    "legend = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Classes\")\n",
    "ax.add_artist(legend)\n",
    "\n",
    "# Add labeling to the plot\n",
    "ax.set_xlabel('x1', fontsize='14')\n",
    "ax.set_ylabel('x2', fontsize='14')\n",
    "ax.set_title('Synthetic data with two classes', fontsize='15');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487cf6c",
   "metadata": {},
   "source": [
    "### Step 1. Establish the Root Node.\n",
    "First, we need to decide what predictor to use for the 1st split and what threshold value we are splitting on. The choosen predictor & threshold will define the **Root Node** of our tree.\n",
    "\n",
    "For candidate splits we try every unique value of each of the predictors.\n",
    "\n",
    "To evaluate the candidate splits we'll use the Gini Impurity Index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5450da",
   "metadata": {},
   "source": [
    "Because we will compare our results to `sklearn` at the end, let's use the same conventions as their `DecisionTreeClassifier`.\n",
    "\n",
    "* Splitting conditions are stated in terms of \"<= threshold\"\n",
    "* Points for which the splitting condition is **true** are placed in the **left** 'child' or 'leaf'. Those for which the condition is false are placed in the right child.\n",
    "\n",
    "This differs from the convention used in the lecture slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates the total Gini impurity index for each value provided\n",
    "def get_total_gini(predictor_values, pred_name, df):\n",
    "    '''\n",
    "    Parameters: an array of _unique_ predictor values,\n",
    "                a name of the predictor (String),\n",
    "                a corresponding dataframe object.\n",
    "    Returns: an array of total Gini index for each provided predictor value.\n",
    "    '''\n",
    "    total_gini = []\n",
    "    \n",
    "    # try each value as a potential split location\n",
    "    for val in predictor_values:\n",
    "        # NOTE: you'll want to use some strategy to avoid division by 0\n",
    "    \n",
    "        # Left Leaf\n",
    "        # counts of each class (1 or 0) to the left of candidate split\n",
    "        left_1 = ...\n",
    "        left_0 = ...\n",
    "        \n",
    "        # total number of points on the left\n",
    "        N_left = ...\n",
    "        # Gini impurity for the left leaf\n",
    "        gini_left = ...\n",
    "    \n",
    "        # Right Leaf\n",
    "        # counts of each class (1 or 0) to the right of candidate split\n",
    "        right_1 = ...\n",
    "        right_0 = ...\n",
    "        # total number of points on the right\n",
    "        N_right = ...\n",
    "        # Gini impurity for the right leaf\n",
    "        gini_right = ...\n",
    "\n",
    "        # total number of points in both leaves\n",
    "        N_total = ...\n",
    "        # Finally append the total weighted gini impurity to total_gini\n",
    "        # total_gini.append(___)\n",
    "    \n",
    "    return total_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187bc52",
   "metadata": {},
   "source": [
    "The `get_total_gini` function takes *unique* predictor values as its first argument. Define these below (and consider why we want to use unique values here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_x1_unique_values) ###\n",
    "\n",
    "# Get unique values of x1\n",
    "x1_unique = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_x2_unique_values) ###\n",
    "\n",
    "# Get unique values of x2\n",
    "x2_unique = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc07d2",
   "metadata": {},
   "source": [
    "Now use `get_total_gini` to find the gini scores for each predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8018e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_x1_total_gini) ###\n",
    "\n",
    "# get total Gini index for x1\n",
    "x1_total_gini = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0de2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_x2_total_gini) ###\n",
    "\n",
    "# get total Gini index for x2\n",
    "x2_total_gini = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da2fd3",
   "metadata": {},
   "source": [
    "Inspect the visualization of your results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb74b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the resulting total Gini indexes for each predictor\n",
    "plt.plot(x1_unique, x1_total_gini, 'r+', label=\"$x_1$\")\n",
    "plt.plot(x2_unique, x2_total_gini, 'b+', label=\"$x_2$\")\n",
    "plt.xlabel(\"Predictor values\", fontsize=\"13\")\n",
    "plt.ylabel(\"Total Gini index\", fontsize=\"13\")\n",
    "plt.title(\"Total gini indexes for x1 and x2 predictors - first split\", fontsize=\"14\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ef334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_splits(x1_unique, x2_unique, x1_total_gini, x2_total_gini):\n",
    "     # predictor providing the split with the lowest gini (x1=0, x2=1)\n",
    "     best_pred = np.argmin([min(x1_total_gini), min(x2_total_gini)])\n",
    "     # index of lowest gini score for best predictor \n",
    "     best_gini_idx = np.argmin([x1_total_gini, x2_total_gini][best_pred])\n",
    "     # best predictor value corresponding to that lowest gini score\n",
    "     best_pred_value = [x1_unique, x2_unique][best_pred][best_gini_idx]\n",
    "     print(\"The lowest total gini score is achieved when splitting on \"+\\\n",
    "          f\"{['x1','x2'][best_pred]} at the value {best_pred_value}.\")\n",
    "          \n",
    "report_splits(x1_unique, x2_unique, x1_total_gini, x2_total_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20950f",
   "metadata": {},
   "source": [
    "**Getting the 1st split threshold**\n",
    "\n",
    "The output above describes the best split among all the candidates. Each candidate split corresponded to a unique predictor value. **But this predictor value will not be our threshold value**. Instead, we use the midpoint *between* this value and the next highest unique value for that predictor in the training data (in this exercise, all data is training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the threshold to split on\n",
    "def get_threshold(unique_values, gini_scores):\n",
    "    # index of lowest gini score\n",
    "    idx = np.argmin(gini_scores)\n",
    "    # threshold is the midpoint between\n",
    "    # the predictor value resulting in lowest gini split\n",
    "    # and the next highest unique predictor value\n",
    "    # (you can assume values are sorted)\n",
    "    threshold = (unique_values[idx] + unique_values[idx+1])/2\n",
    "    return threshold\n",
    "\n",
    "x2_threshold = ...\n",
    "print(f\"Our threshold will be {x2_threshold}\")\n",
    "\n",
    "# Test that we got the expected result\n",
    "np.testing.assert_allclose(159.5, x2_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e1f15",
   "metadata": {},
   "source": [
    "### Step 2. Let's make our first split. \n",
    "\n",
    "We'll use some helper functions to assist with plotting the decision regions we get from our first split. \n",
    "\n",
    "`get_split_labels` determines the classification within each region based on the majority class within that region in the training data.\n",
    "\n",
    "`predict_class` takes vectors of `x1` and `x2` values and returns a vector of predicted class labels. We predict on dummy values created with `np.meshgrid` and use the results with `plt.contourf` to plot colored decision regions.\n",
    "\n",
    "In keeping with the convention used by `sklearn`, all points in our root node that are less than or equal to our threshold will be placed in the 'left' childe node. And the rest will go on in the 'right' child node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_labels(splits):\n",
    "    '''\n",
    "    Parameters:\n",
    "        splits: List of ('predictor name', threshold) tuples\n",
    "                Ex: [('x1', 42), ('x2', 109)]\n",
    "    Returns: List of dictionaries, one for each split. \n",
    "             Dictionaries contain class labels for each side of the split\n",
    "    '''\n",
    "    split_labels = []\n",
    "    region = tree_df\n",
    "    for pred, thresh in splits:\n",
    "        region_labels = {\n",
    "            'left': region.loc[region[pred] <= thresh, 'y'].mode().values[0],\n",
    "            'right': region.loc[region[pred] > thresh, 'y'].mode().values[0]\n",
    "        }\n",
    "        split_labels.append(region_labels)\n",
    "        region = region[region[pred] <= thresh]\n",
    "    return split_labels\n",
    "\n",
    "# Example of how get_split_labels works\n",
    "splits = [('x2', x2_threshold)]\n",
    "split_labels = get_split_labels(splits)\n",
    "print('class labels for the children of the root node:', split_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(x1, x2, splits):\n",
    "    # get split labels to use when predicting\n",
    "    split_labels = get_split_labels(splits)\n",
    "    y_hats = []\n",
    "    # iterate over each data point\n",
    "    for x1_i, x2_i in zip(x1.ravel(), x2.ravel()):\n",
    "        # dict lets us specify a predictor based on split rule\n",
    "        obs = {'x1': x1_i, 'x2': x2_i}\n",
    "        # apply each split rule\n",
    "        for n_split, (pred, thresh) in enumerate(splits):\n",
    "            # left\n",
    "            if obs[pred] <= thresh:\n",
    "                if n_split == len(splits)-1:\n",
    "                    y_hats.append(split_labels[n_split]['left'])\n",
    "            # right\n",
    "            else:\n",
    "                y_hats.append(split_labels[n_split]['right'])\n",
    "                break\n",
    "    return np.array(y_hats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e6d51",
   "metadata": {},
   "source": [
    "Now we are ready to plot our split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7177cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the split:\n",
    "# Create figure of specific size and the axes objects\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Scatter the data points\n",
    "# Other colormaps could be found here:\n",
    "# https://stackoverflow.com/questions/34314356/how-to-view-all-colormaps-available-in-matplotlib\n",
    "scatter = ax.scatter(tree_df['x1'], tree_df['x2'], c=tree_df['y'], cmap='rainbow')\n",
    "\n",
    "# Create a legend object with title \"Classes\" and specified location on the plot\n",
    "legend = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Classes\")\n",
    "ax.add_artist(legend)\n",
    "\n",
    "# Split line\n",
    "ax.hlines(x2_threshold, xmin=0, xmax=500,\n",
    "          color ='black', lw = 2, ls=':', label='new split')\n",
    "ax.legend()\n",
    "\n",
    "# Add labeling to the plot\n",
    "ax.set_xlabel('x1', fontsize='14')\n",
    "ax.set_ylabel('x2', fontsize='14')\n",
    "ax.set_title('The first split of the data', fontsize='16')\n",
    "\n",
    "# Plot decision regions\n",
    "# dummy x1 & x2 grid values to predict on\n",
    "eps = 5 # padding for the grid\n",
    "xx1, xx2 = np.meshgrid(np.arange(tree_df['x1'].min()-eps, tree_df['x1'].max()+eps, 1),\n",
    "                       np.arange(tree_df['x2'].min()-eps, tree_df['x2'].max()+eps, 1))\n",
    "# predict class labels on grid points\n",
    "class_pred = predict_class(xx1, xx2, splits)\n",
    "# contour plot for decision regions\n",
    "plt.contourf(xx1, xx2, class_pred.reshape(xx1.shape), alpha=0.2, zorder=-1, cmap=plt.cm.coolwarm);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856c0ea",
   "metadata": {},
   "source": [
    "We'll create a new DataFrame, `first_split_df` in which all `x2` values are less than or equal to `x2_threshold`.\n",
    "\n",
    "This DataFrame contains the points that end up in the region corresponding to the \"left leaf\" or \"left child\" of the root node. We'll use it in the next section where we further split this region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_split_df  = ...\n",
    "# Peak at the result\n",
    "first_split_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87973dc6",
   "metadata": {},
   "source": [
    "### Step 3. Making the second split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb933f9f",
   "metadata": {},
   "source": [
    "Now we'll run the same function as above using our new df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide unique values from our new dataframe\n",
    "x1_unique_2split = np.unique(first_split_df['x1'].values)\n",
    "x2_unique_2split = np.unique(first_split_df['x2'].values)\n",
    "\n",
    "tot_gini_x1_2split = get_total_gini(x1_unique_2split, 'x1', first_split_df)\n",
    "tot_gini_x2_2split = get_total_gini(x2_unique_2split, 'x2', first_split_df)\n",
    "\n",
    "plt.plot(x1_unique_2split, tot_gini_x1_2split, 'r+', label='$x_1$')\n",
    "plt.plot(x2_unique_2split, tot_gini_x2_2split, 'b+', label='$x_2$')\n",
    "plt.xlabel(\"Predictor values\", fontsize=\"13\")\n",
    "plt.ylabel(\"Total Gini index\", fontsize=\"13\")\n",
    "plt.title(\"Total Gini indexes for x1 and x2 predictors - second split\", fontsize=\"14\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_splits(x1_unique_2split, x2_unique_2split,\n",
    "              tot_gini_x1_2split, tot_gini_x2_2split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de53203",
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_second_threshold) ###\n",
    "\n",
    "# The value to split on\n",
    "x1_threshold_2split = ...\n",
    "print(\"x1 2nd split threshold:\", x1_threshold_2split)\n",
    "\n",
    "# Test that we got the expected result\n",
    "np.testing.assert_allclose(137.5, x1_threshold_2split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the split:\n",
    "# Create figure of specific size and the axes objects\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Scatter the data points\n",
    "scatter = ax.scatter(tree_df['x1'], tree_df['x2'], c=tree_df['y'], cmap='rainbow')\n",
    "\n",
    "# Create a legend object with title \"Classes\" and specified location on the plot\n",
    "legend = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Classes\")\n",
    "ax.add_artist(legend)\n",
    "\n",
    "# Split lines\n",
    "ax.hlines(x2_threshold, xmin=0, xmax=500,\n",
    "          color ='black', lw = 0.5, ls='--')\n",
    "ax.vlines(x1_threshold_2split, ymin=0, ymax=x2_threshold,\n",
    "          color ='black', lw = 2, ls=':', label='new split')\n",
    "ax.legend()\n",
    "\n",
    "# Plot decision regions\n",
    "# predict class labels on grid points\n",
    "class_pred = predict_class(xx1, xx2, [('x2', x2_threshold), ('x1', x1_threshold_2split)])\n",
    "# contour plot for decision regions\n",
    "plt.contourf(xx1, xx2, class_pred.reshape(xx1.shape), alpha=0.2, zorder=-1, cmap=plt.cm.coolwarm)\n",
    "\n",
    "# Add labeling to the plot\n",
    "ax.set_xlabel('x1', fontsize='13')\n",
    "ax.set_ylabel('x2', fontsize='13')\n",
    "ax.set_title('First and second splits on the data', fontsize='14');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc56123",
   "metadata": {},
   "source": [
    "### Step 4. Stop splitting when the region formed is pure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aea582",
   "metadata": {},
   "source": [
    "Let's split the data and check the values to the right of the threshold:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0971742",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_right_intern_node_df  = first_split_df[first_split_df['x1'] > x1_threshold_2split]\n",
    "first_right_intern_node_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e0583e",
   "metadata": {},
   "source": [
    "We can see that this region is pure; all the class labels are `1`. There is no need to perform further splits on this region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ca3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_right_intern_node_df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91edc00",
   "metadata": {},
   "source": [
    "### Step 5. Keep doing splits on impure regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d68ecb",
   "metadata": {},
   "source": [
    "We stopped spliting on the right child of the second split because it was all one class, however the region represented by the left child is not pure.\n",
    "\n",
    "In the decision tree algorithm we would keep splitting it recursively till every resulting region will become pure or we encounter another stopping condition, such as max depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558c004",
   "metadata": {},
   "source": [
    "Use the correct predictor and threshold to subset `first_split_df` to include only those points whose values are in the *left child* of our 2nd split. \n",
    "\n",
    "Store the resulting dataframe as `second_split_left_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8bc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_split_left_df  = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433977cf",
   "metadata": {},
   "source": [
    "Observe that *this* node is not pure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbacc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_split_left_df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3511d59",
   "metadata": {},
   "source": [
    "Let's perform a final split on this impure region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e562dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the predictor and threshold for the split\n",
    "\n",
    "# get unique values of x1 and x2 in this region\n",
    "x1_unique_3split = np.unique(second_split_left_df['x1'].values)\n",
    "x2_unique_3split = np.unique(second_split_left_df['x2'].values)\n",
    "\n",
    "# Get total gini index for each predictor\n",
    "tot_gini_x1_3split = get_total_gini(x1_unique_3split, 'x1', second_split_left_df)\n",
    "tot_gini_x2_3split = get_total_gini(x2_unique_3split, 'x2', second_split_left_df)\n",
    "\n",
    "plt.plot(x1_unique_3split, tot_gini_x1_3split, 'r+', label='$x_1$')\n",
    "plt.plot(x2_unique_3split, tot_gini_x2_3split, 'b+', label='$x_2$')\n",
    "plt.xlabel(\"Predictor values\", fontsize=\"13\")\n",
    "plt.ylabel(\"Total Gini index\", fontsize=\"13\")\n",
    "plt.title(\"Total Gini indexes for x1 and x2 predictors - third split\", fontsize=\"14\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_splits(x1_unique_3split, x2_unique_3split,\n",
    "              tot_gini_x1_3split, tot_gini_x2_3split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e42fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_third_threshold) ###\n",
    "\n",
    "# The value to split on\n",
    "x2_threshold_3split = ...\n",
    "\n",
    "print(\"x2 3rd split threshold:\", x2_threshold_3split)\n",
    "# Test that we got the expected result\n",
    "np.testing.assert_allclose(141.0, x2_threshold_3split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddbe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the split:\n",
    "# Create figure of specific size and the axes objects\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Scatter the data points\n",
    "scatter = ax.scatter(tree_df['x1'], tree_df['x2'], c=tree_df['y'], cmap='rainbow')\n",
    "\n",
    "# Create a legend object with title \"Classes\" and specified location on the plot\n",
    "legend = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Classes\")\n",
    "ax.add_artist(legend)\n",
    "\n",
    "# Split lines\n",
    "ax.hlines(x2_threshold, xmin=0, xmax=500,\n",
    "          color ='black', lw = 0.5, ls='--')\n",
    "ax.vlines(x1_threshold_2split, ymin=0, ymax=x2_threshold,\n",
    "          color ='black', lw = 0.5, ls='--')\n",
    "ax.hlines(x2_threshold_3split, xmin=0, xmax=x1_threshold_2split,\n",
    "          color ='black', lw = 2, ls=':', label='new split')\n",
    "ax.legend()\n",
    "\n",
    "# Plot decision regions\n",
    "# predict class labels on grid points\n",
    "class_pred = predict_class(xx1, xx2, [('x2', x2_threshold),\n",
    "                                      ('x1', x1_threshold_2split),\n",
    "                                      ('x2', x2_threshold_3split)])\n",
    "# contour plot for decision regions\n",
    "plt.contourf(xx1, xx2, class_pred.reshape(xx1.shape), alpha=0.2, zorder=-1, cmap=plt.cm.coolwarm)\n",
    "\n",
    "# Add labeling to the plot\n",
    "ax.set_xlabel('x1', fontsize='13')\n",
    "ax.set_ylabel('x2', fontsize='13')\n",
    "ax.set_title('First, second, and third splits on the data', fontsize='14');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f172e42",
   "metadata": {},
   "source": [
    "The two leaf nodes resulting from this split are pure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the split\n",
    "# Get the left leaf node\n",
    "left_final_leaf_df  = second_split_left_df[second_split_left_df['x2'] <= x2_threshold_3split]\n",
    "# Confirm the purity of the final leaf\n",
    "left_final_leaf_df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbab98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the right leaf node\n",
    "right_final_leaf_df = second_split_left_df[second_split_left_df['x2'] > x2_threshold_3split]\n",
    "# Confirm the putity of the final leaf\n",
    "right_final_leaf_df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e998e5a",
   "metadata": {},
   "source": [
    "## Comparing to SKLearn Implementation\n",
    "We have just finished the left branch of the decision tree for this data. Now Let's compare our manual results with what sklearn DecisionTreeClassifier class would do. We will use a handy tree module from sklearn to visualize the produced tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce986ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into predictor matrix and target series\n",
    "X = tree_df[['x1','x2']]\n",
    "y = tree_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the tree to the data\n",
    "sklearn_tree = DecisionTreeClassifier(max_depth=3)\n",
    "sklearn_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ab0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree\n",
    "tree.plot_tree(sklearn_tree, fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069afeb3",
   "metadata": {},
   "source": [
    "**As we can see above the left tree branch on the sklearn tree looks just like what we did manually above!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cad73-2296-41aa-b862-45729d2834b3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03337952",
   "metadata": {},
   "source": [
    "## COVID Risk Classification Scenarios\n",
    "\n",
    "Even with the ROC curve as a tool, we cannot really tell which model to use.\n",
    "\n",
    "What metric matters most for decision‚Äëmaking?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68249f",
   "metadata": {},
   "source": [
    "### Scenario 1 ‚Äî üáßüá∑ Brazil\n",
    "\n",
    "In Brazil, the new covid variant is contagious and infects many citizens.\n",
    "Brazilian officials, however, dictate that hospitals do not classify many people at 'high' risk to avoid bad press and subsequent political global backlash.\n",
    "To model this scenario well, we need the best classifier with the following restriction:\n",
    "\n",
    "<img src=\"fig/brazil.png\" alt=\"News article about the Covid situation in Brazil\" style=\"zoom:50%;\" />\n",
    "\n",
    "\n",
    "\n",
    "**Constraint:**\n",
    "$$TPR + FPR \\le 0.5$$\n",
    "\n",
    "*Goal:* Limit total positive classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258642c1",
   "metadata": {},
   "source": [
    "### Scenario 2 ‚Äî üá©üá™ Germany\n",
    "\n",
    "German officials want the fatality ratio to be as low as possible.\n",
    "Thus, it is imperative to find cases that need urgent attention and give them the best chance of survival.\n",
    "Thus, we need the best classifier with the following restriction:\n",
    "\n",
    "<img src=\"fig/germany.png\" alt=\"News article about the Covid situation in Germany\" style=\"zoom:50%;\" />\n",
    "\n",
    "\n",
    "**Constraint:**\n",
    "$$TPR \\ge 0.85$$\n",
    "\n",
    "*Goal:* Maximize ability to catch true severe cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d07beb",
   "metadata": {},
   "source": [
    "### Scenario 3 ‚Äî üáÆüá≥ India\n",
    "\n",
    "India has only 1 million beds left and there are already 2 million people suspected of having the disease.\n",
    "Officials need to work out a strategy to find the people who are in the most need of urgent care.\n",
    "This restriction to model this scenario well is the following:\n",
    "\n",
    "\n",
    "<img src=\"fig/india.png\" alt=\"News article about the Covid situation in India\" style=\"zoom:50%;\" />\n",
    "\n",
    "**Constraint:**\n",
    "$$TPR + FPR \\le 1$$\n",
    "\n",
    "*Goal:* Balanced trade‚Äëoff for a constrained healthcare system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7dda56",
   "metadata": {},
   "source": [
    "### ROC‚ÄëBased Model Choice Discussion\n",
    "\n",
    "Insert ROC curve and compare classifiers under each constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b5724",
   "metadata": {},
   "source": [
    "Given that we have produced a plot similar to the one shown here, we would want to find the best model for each of the three cases.\n",
    "\n",
    "<img src=\"fig/roc_curve.png\" alt=\"ROC curve plot for all 3 countries; Brazil, Germany, and India\" style=\"zoom:50%;\" />\n",
    "\n",
    "\n",
    "What the chart means\n",
    "### Understanding ROC Axes: FPR & TPR\n",
    "\n",
    "| Axis   | Meaning                                                                     |\n",
    "| ------ | --------------------------------------------------------------------------- |\n",
    "| x-axis | False Positive Rate (FPR) ‚Äî *‚Äúhow many healthy people we classify as sick‚Äù* |\n",
    "| y-axis | True Positive Rate (TPR) ‚Äî *‚Äúhow many sick people we correctly detect‚Äù*     |\n",
    "\n",
    "Higher-left corner = best-performing region.\n",
    "\n",
    "\n",
    "### Choice of Classifier\n",
    "\n",
    "Based on the constraints, we have the following choice of classifier:\n",
    "\n",
    "**BRAZIL** : Logistic regression with a high threshold\n",
    "\n",
    "<img src=\"fig/classification_metrics_bestmodel2.png\" alt=\"ROC curve plot for all 3 countries; Brazil, Germany and India - with Brazil threshold highlighted\" style=\"zoom:50%;\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**GERMANY** : Logistic regression with a low threshold\n",
    "\n",
    "<img src=\"fig/classification_metrics_bestmodel3.png\" alt=\"ROC curve plot for all 3 countries; Brazil, Germany and India - with Germany threshold highlighted\" style=\"zoom:50%;\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**INDIA** : kNN classifier with a moderate threshold\n",
    "\n",
    "<img src=\"fig/classification_metrics_bestmodel4.png\" alt=\"ROC curve plot for all 3 countries; Brazil, Germany and India - with India threshold highlighted\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb3268",
   "metadata": {},
   "source": [
    "## üß† Summary\n",
    "\n",
    "* **Models alone never solve the problem**\n",
    "* **Policy + context determines the ‚Äúbest‚Äù classifier**\n",
    "* ROC curves + constraints = **decision system**\n",
    "\n",
    "Different countries ‚Üí *different operating points, even with the same models.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf94d4b-7a15-4399-8fcd-74f163273561",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4227f",
   "metadata": {},
   "source": [
    "# Additional material"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecf0d1ca-d3d3-4fc6-af11-59d2506b4bbe",
   "metadata": {},
   "source": [
    "## Decision Tree Spam Classifier Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "108c780d-2d23-4a6d-8540-a1d404ad638c",
   "metadata": {},
   "source": [
    "We will be working with a spam email dataset. The dataset has 57 predictors with a response variable called `Spam` that indicates whether an email is spam or not spam. The goal is to be able to create a classifier or method that acts as a spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = pd.read_csv('data/spam.csv')\n",
    "display(spam_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49421ec4-378c-4a96-958e-6ab82e2718b1",
   "metadata": {},
   "source": [
    "The predictors are all quantitative. They represent certain features  of an email like the frequency of the word 'discount.' The we will use the binary `spam` variable in the final column as our response for classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c76bae4e-f1c3-49d9-b7d1-56afe200cf94",
   "metadata": {},
   "source": [
    "Link to description : https://archive.ics.uci.edu/ml/datasets/spambase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab525d6-101d-4e23-b623-f3d8aa25873a",
   "metadata": {},
   "source": [
    "#### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split spam_df into train and test data with a random seed of 109\n",
    "data_train, data_test = train_test_split(spam_df, random_state=0, test_size=.2, stratify=spam_df.spam)\n",
    "\n",
    "# Split predictor and response columns\n",
    "X_train, y_train = data_train.drop(['spam'], axis=1), data_train['spam']\n",
    "X_test , y_test  = data_test.drop(['spam'] , axis=1), data_test['spam']\n",
    "\n",
    "print(\"Shape of Training Set :\", data_train.shape)\n",
    "print(\"Shape of Testing Set :\" , data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad4e34f2-436f-4648-ac88-1b6e8d3a5e90",
   "metadata": {},
   "source": [
    "We can check that the proportion of spam cases is roughly evenly represented in both the training and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Percentage of Spam in Train and Test Set\n",
    "pct_spam_tr = 100*y_train.mean()\n",
    "pct_spam_te = 100*y_test.mean()\n",
    "                                                  \n",
    "print(f\"Percentage of Spam in Training Set \\t : {pct_spam_tr:0.2f}%\")\n",
    "print(f\"Percentage of Spam in Testing Set \\t : {pct_spam_te:0.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22e5819b-8a6e-4edd-af53-e52ead9db5e7",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "#### Fitting an Optimal Single Decision Tree (by Depth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bf53d03-f0c3-4854-817f-c1654e43cee2",
   "metadata": {},
   "source": [
    "Here, for each candidate `max_depth` and `criterion` combination, we fit a single tree to our spam training data using 5-fold cross validation.\n",
    "\n",
    "We store the CV accuracy scores in a DataFrame along with the hyperparmeter settings that generated them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a514db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimal depth of trees\n",
    "\n",
    "df = pd.DataFrame(columns=['criterion', 'depth', 'all_cv', 'mean_cv'])\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "first_depth = 2\n",
    "final_depth = 30\n",
    "step = 2\n",
    "\n",
    "results = []\n",
    "for cur_criterion in criterion:      \n",
    "    for max_depth in range(first_depth, final_depth+1, step):\n",
    "        dt = DecisionTreeClassifier(criterion=cur_criterion , max_depth=max_depth)\n",
    "        scores = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, n_jobs=-1)\n",
    "        \n",
    "        cur_results = {'criterion': cur_criterion,\n",
    "                      'depth': max_depth,\n",
    "                      'all_cv': scores,\n",
    "                      'mean_cv': scores.mean()}\n",
    "        results.append(cur_results)\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d58fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cabe4f7-0d26-4a2a-a99f-1a135b8ed27e",
   "metadata": {},
   "source": [
    "Some dataframe manipulations for our x,y construction for the plot below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d88772-74e1-47b9-ac8f-9145a9c720f2",
   "metadata": {},
   "source": [
    "#### CV Accuracy by Max Depth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "350a7c16-18e8-4611-8615-4d447df42511",
   "metadata": {},
   "source": [
    "We can then visualize the validation accuracy for the different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "plt.plot(df[df.criterion == 'gini'].depth,\n",
    "         df[df.criterion == 'gini'].mean_cv, 'b-', marker='o', alpha = 0.6, label='Gini')\n",
    "plt.plot(df[df.criterion == 'entropy'].depth,\n",
    "         df[df.criterion == 'entropy'].mean_cv, 'r-', marker='o', alpha = 0.6, label='Entropy')\n",
    "plt.ylabel(\"Cross Validation Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "plt.legend()\n",
    "plt.grid(alpha = 0.3)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a92bc900-1af2-4615-8b13-e124df981039",
   "metadata": {},
   "source": [
    "#### Variance of CV Accuracy\n",
    "Let's visualize a plot with the Confidence Bands!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24027035-9af3-4ed6-9d1d-64ae470151f9",
   "metadata": {},
   "source": [
    "Also, if we wanted to get **the Confidence Bands of these results**, how would we? It's as simple as a combination of getting variance using ```scores.std()``` and ```plt.fill_between()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gini = df[df['criterion'] == 'gini']\n",
    "df_entropy = df[df['criterion'] == 'entropy']\n",
    "\n",
    "x_gini = df_gini['depth'].values.astype(float)\n",
    "y_gini = df_gini['mean_cv'].values.astype(float)\n",
    "\n",
    "x_entropy = df_entropy['depth'].values.astype(float)\n",
    "y_entropy = df_entropy['mean_cv'].values.astype(float)\n",
    "\n",
    "stds_gini = np.array([ np.std(scores) for scores in df_gini['all_cv']], dtype = float) \n",
    "stds_entropy = np.array([ np.std(scores) for scores in df_entropy['all_cv']], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 5))\n",
    "\n",
    "#Plot\n",
    "axes[0].fill_between(df.loc[df.criterion == 'gini'].depth, y_gini + stds_gini, \n",
    "                     y_gini - stds_gini, alpha=0.2)\n",
    "axes[0].plot(x_gini, y_gini, 'b-', marker='o')\n",
    "axes[0].set_ylabel(\"Cross Validation Accuracy\")\n",
    "axes[0].set_title('Variation of Accuracy with Depth - Single Decision Tree')\n",
    "axes[0].legend(['std','Gini'])\n",
    "axes[0].grid(alpha = 0.3)\n",
    "\n",
    "axes[1].fill_between(x_entropy, y_entropy + stds_entropy, \n",
    "                     y_entropy - stds_entropy, \n",
    "                     color = 'r', alpha=0.2)\n",
    "axes[1].plot(x_entropy, y_entropy, 'r-', marker='o')\n",
    "axes[1].set_ylabel(\"Cross Validation Accuracy\")\n",
    "axes[1].set_xlabel(\"Maximum Depth\")\n",
    "axes[1].legend(['std','Entropy'])\n",
    "axes[1].grid(alpha = 0.3)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "312f7b75-3372-45fe-a457-b17a268d0dec",
   "metadata": {},
   "source": [
    "#### Box plots of CV Ginit Impurity\n",
    "Let's visualize a boxplot! (**Gini impurity** only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35100420-b86d-4eee-9bf2-a03bb2d22555",
   "metadata": {},
   "source": [
    "If we want to display it as a boxplot we first construct a dataframe with all the scores and second we use ```sns.boxplot(...)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfc5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_gini.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99236e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = range(first_depth, final_depth + 1, step)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.boxplot([df_gini.loc[df_gini.depth==d, 'all_cv'].values[0] for d in ds])\n",
    "plt.scatter(range(1,len(ds)+1), df_gini.mean_cv, color='red', alpha=0.3, label='Mean CV Acc')\n",
    "plt.xticks(range(1,len(ds)+1), labels=ds)\n",
    "plt.ylabel(\"cross-validation accuracy\")\n",
    "plt.xlabel(\"max depth\")\n",
    "plt.title(\"Spam Classifier Trees (Gini)\")\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c398f2de-6a18-4431-8694-f0b8933043f3",
   "metadata": {},
   "source": [
    "**Question:** Which depth are you going to pick?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a14454f6-2293-48dd-8ad3-9849e84c97bd",
   "metadata": {},
   "source": [
    "#### Best Depth by Metric\n",
    "**Let's extract the best_depth value from these two dataframes, *df_gini* and *df_entropy*.**\n",
    "\n",
    "We need to create the new variable *best_depth* for each dataframe. \n",
    "\n",
    "How to get the index of the maximum value from the given array?\n",
    "\n",
    "```hint: np.argmax(target array)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e822e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do?\n",
    "\n",
    "mean_CV_acc_gini = df_gini['mean_cv']\n",
    "mean_CV_acc_entropy = df_entropy['mean_cv']\n",
    "\n",
    "best_idx_gini = np.argmax(mean_CV_acc_gini)\n",
    "best_idx_entropy = np.argmax(mean_CV_acc_entropy)\n",
    "\n",
    "best_depth_gini = df_gini['depth'].iloc[best_idx_gini]\n",
    "best_depth_entropy = df_entropy['depth'].iloc[best_idx_entropy]\n",
    "\n",
    "print('The best depth based on Gini impurity was found to be: ', best_depth_gini)\n",
    "print('The best depth based on Entropy was found to be: ', best_depth_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaute the performance at the best depth\n",
    "model_tree_gini = DecisionTreeClassifier(max_depth=best_depth_gini, criterion = 'gini')\n",
    "model_tree_entropy = DecisionTreeClassifier(max_depth=best_depth_entropy, criterion ='entropy')\n",
    "\n",
    "model_tree_gini.fit(X_train, y_train)\n",
    "model_tree_entropy.fit(X_train, y_train)\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set (Gini Impurity)\n",
    "acc_trees_train_gini = accuracy_score(y_train, model_tree_gini.predict(X_train))\n",
    "acc_trees_test_gini  = accuracy_score(y_test,  model_tree_gini.predict(X_test))\n",
    "\n",
    "print(\"================ [Gini Impurity] ================\")\n",
    "print(\"Simple Decision Trees: Accuracy, Training Set \\t : {:.2%}\".format(acc_trees_train_gini))\n",
    "print(\"Simple Decision Trees: Accuracy, Testing Set \\t : {:.2%}\".format(acc_trees_test_gini))\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set (Entropy)\n",
    "acc_trees_train_entropy = accuracy_score(y_train, model_tree_entropy.predict(X_train))\n",
    "acc_trees_test_entropy = accuracy_score(y_test,  model_tree_entropy.predict(X_test))\n",
    "\n",
    "print(\"\\n================ [Entropy] ================\")\n",
    "print(\"Simple Decision Trees: Accuracy, Training Set \\t : {:.2%}\".format(acc_trees_train_entropy))\n",
    "print(\"Simple Decision Trees: Accuracy, Testing Set \\t : {:.2%}\".format(acc_trees_test_entropy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b77c288-d913-426a-acea-53c190892533",
   "metadata": {},
   "source": [
    "#### Confusion Matrices\n",
    "Let's visualize a confusion matrix with ```plot_confusion_matrix```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8abc096a-d6eb-45ae-839b-913c0a71858c",
   "metadata": {},
   "source": [
    "#### How to visualize the classification result using a Confusion matrix? ####\n",
    "\n",
    "<img src=\"fig/confusion_matrix.png\" alt=\"classification error\" width=\"300\"/>\n",
    "\n",
    "<img src=\"fig/confusion_matrix2.png\" alt=\"classification error\" width=\"400\"/>\n",
    "\n",
    "*source: wikipedia*\n",
    "\n",
    "Here's how can use the sklearn function, **plot_confusion_matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d56df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,8))\n",
    "ConfusionMatrixDisplay.from_estimator(model_tree_gini, X_test, y_test, cmap=plt.cm.Blues, ax = axes[0]);\n",
    "ConfusionMatrixDisplay.from_estimator(model_tree_entropy, X_test, y_test, cmap=plt.cm.Blues, ax = axes[1])\n",
    "axes[0].set_title('Simple Decision Tree - Gini')\n",
    "axes[1].set_title('Simple Decision Tree - Entropy')\n",
    "# plt.rc('font', size=18)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2b2ead8-e0c7-4472-8d13-22eb69a3a5a7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a20da-dd3b-4fd2-8496-b984b3c62dde",
   "metadata": {},
   "source": [
    "## Preprocessing for Decision Trees\n",
    "\n",
    "Unlike many other models, decision trees have some nice properties when it comes to preprocessing:\n",
    "\n",
    "1. **Scaling**: Trees don't require feature scaling because they use thresholds rather than distances\n",
    "   - No need for StandardScaler or MinMaxScaler\n",
    "   - Trees make splits based on relative ordering, not absolute values\n",
    "\n",
    "2. **Categorical Variables**: \n",
    "   - For binary categories, any encoding works equally well\n",
    "   - For multi-class categories:\n",
    "     - One-hot encoding is preferred\n",
    "     - No need to drop_first (unlike linear models) since trees can handle the redundancy\n",
    "```python\n",
    "# Example of proper categorical encoding for trees\n",
    "X_encoded = pd.get_dummies(X, columns=['categorical_column'])\n",
    "# No need for: drop_first=True\n",
    "```\n",
    "\n",
    "3. **Missing Values**: \n",
    "   - Trees can handle missing values naturally (though sklearn's implementation doesn't)\n",
    "   - Consider using SimpleImputer with strategy='most_frequent' for categorical\n",
    "   - Use strategy='median' for numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd3675-c83b-4298-8a71-4696129d780e",
   "metadata": {},
   "source": [
    "## Handling Class Imbalances\n",
    "\n",
    "Class imbalance occurs when some classes have many more samples than others. This is common in real-world scenarios like spam detection or fraud detection. With imbalanced datasets, accuracy can be misleading - a model could achieve high accuracy by simply predicting the majority class!\n",
    "\n",
    "There are several approaches to handle class imbalances:\n",
    "\n",
    "1. **Class Weights**: Tell the model to pay more attention to minority classes\n",
    "   \n",
    "```python\n",
    "# Add weights inversely proportional to class frequencies\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', \n",
    "                                     classes=np.unique(y_train),\n",
    "                                     y=y_train)\n",
    "                                   \n",
    "dt = DecisionTreeClassifier(class_weight='balanced')  # Or pass dict of weights\n",
    "```\n",
    "\n",
    "2. **Upsampling**: Replicate minority class samples\n",
    "```python\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "print('Original dataset shape:', Counter(y_train))\n",
    "print('Resampled dataset shape:', Counter(y_train_ros))\n",
    "```\n",
    "\n",
    "3. **SMOTE**: Create synthetic minority samples (requires a pip install)\n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "print('Original dataset shape:', Counter(y_train))\n",
    "print('Resampled dataset shape:', Counter(y_train_sm))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076bb89d-2f13-47e4-9e89-5037deb7a2f3",
   "metadata": {},
   "source": [
    "## Alternative Metrics to Accuracy (revisted)\n",
    "\n",
    "When dealing with imbalanced classes, accuracy can be misleading. Consider these alternatives:\n",
    "\n",
    "1. **Precision**: Of the positive predictions, how many were correct?\n",
    "   - Important when false positives are costly\n",
    "   - Example: Spam detection (don't want to block legitimate emails)\n",
    "\n",
    "2. **Recall**: Of the actual positive cases, how many did we catch?\n",
    "   - Important when false negatives are costly\n",
    "   - Example: Disease detection (don't want to miss sick patients)\n",
    "\n",
    "3. **F1 Score**: Harmonic mean of precision and recall\n",
    "   - Balances precision and recall\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get comprehensive metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# For binary classification, you can of course also plot the ROC curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "RocCurveDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5cb09-b2ae-4a2a-bf24-1c3e0cb30cdd",
   "metadata": {},
   "source": [
    "**üåà The End**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc25217-f427-4d47-9555-005c21cbdc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
